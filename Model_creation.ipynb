{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_mapper = {\n",
    "'subst':  'rzecz',\n",
    "'depr':   'rzecz',\n",
    "'num':    'rzecz',\n",
    "'numcol': 'rzecz',\n",
    "'adj':    'przym',\n",
    "'adja':   'przym',\n",
    "'adjp':   'przym',\n",
    "'adjc':   'przym',\n",
    "'adv':    'przys',\n",
    "'ppron12':'rzecz',\n",
    "'ppron3': 'rzecz',\n",
    "'siebie': 'rzecz',\n",
    "'fin':    'czas',\n",
    "'bedzie': 'czas',\n",
    "'aglt':   'czas',\n",
    "'praet':  'czas',\n",
    "'impt':   'czas',\n",
    "'imps':   'czas',\n",
    "'inf':    'czas',\n",
    "'pcon':   'czas',\n",
    "'pant':   'czas',\n",
    "'ger':    'czas',\n",
    "'pact':   'czas',\n",
    "'ppas':   'czas',\n",
    "'winien': '?',\n",
    "'pred':   '?',\n",
    "'prep':   '?',\n",
    "'conj':   '?',\n",
    "'comp':   '?',\n",
    "'qub':    '?',\n",
    "'brev':   '?',\n",
    "'burk':   '?',\n",
    "'interj': '?',\n",
    "'interp': '?',\n",
    "'xxx':    '?',\n",
    "'ign':    '?',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToWordsDf(xml_path, wordsDf):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    for tok in root.iter('tok'):\n",
    "        for lex in tok.iter('lex'):\n",
    "            if \"disamb\" in lex.attrib and lex.attrib['disamb']==\"1\":\n",
    "                base = lex.find('base').text\n",
    "                ctag = lex.find('ctag').text\n",
    "                partOfSpeach = gram_mapper[ctag.split(\":\")[0]]\n",
    "                if wordsDf[wordsDf['base'] == base].empty:\n",
    "                    record = pd.DataFrame(data={\"base\": [base], \"parts_of_speech\": [partOfSpeach], \"n_occurrences\": [1]})\n",
    "                    wordsDf = pd.concat([wordsDf, record], ignore_index=True)\n",
    "                else:\n",
    "                    values = wordsDf.loc[wordsDf['base'] == base, [\"n_occurrences\"]]\n",
    "                    wordsDf.loc[wordsDf['base'] == base, [\"n_occurrences\"]] = values + 1\n",
    "    return wordsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWordsDf(xmls_train_dir, save=None):\n",
    "    wordsDf = pd.DataFrame(columns=[\"base\", \"parts_of_speech\", \"n_occurrences\"])\n",
    "    for fileName in tqdm(os.listdir(xmls_train_dir)):\n",
    "        wordsDf = addToWordsDf(xmls_train_dir+fileName, wordsDf)\n",
    "        if save is not None:\n",
    "            wordsDf.to_csv(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostFreq(wordsDf, partOfSpeach, vec_size):\n",
    "    return wordsDf[wordsDf[\"parts_of_speech\"] == partOfSpeach].sort_values(by=['n_occurrences'], ascending=False).head(vec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(xmls_dir, mostFreq):\n",
    "    X, y = [], []\n",
    "    for train_xml in tqdm(os.listdir(xmls_dir)):\n",
    "        x_sample, y_sample = getSample(xmls_dir + train_xml, mostFreq)\n",
    "        X.append(x_sample)\n",
    "        y.append(y_sample)\n",
    "    return X, y\n",
    "\n",
    "def getSample(xml_file_path, mostFreq):\n",
    "    record_bases = getTextBases(xml_file_path)\n",
    "    x = []\n",
    "    fileName = os.path.basename(xml_file_path)\n",
    "    fileName = os.path.splitext(fileName)[0]\n",
    "    y = re.findall(r'[a-zA-Z\\-]+', fileName)[0]\n",
    "    for base in mostFreq:\n",
    "        x.append(record_bases.count(base))\n",
    "    return x, y\n",
    "\n",
    "def getTextBases(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    bases = []\n",
    "    for tok in root.iter('tok'):\n",
    "        for lex in tok.iter('lex'):\n",
    "            if \"disamb\" in lex.attrib and lex.attrib['disamb']==\"1\":\n",
    "                base = lex.find('base').text\n",
    "                bases.append(base)\n",
    "    return bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slenderize(old_X, n_col):\n",
    "    X = []\n",
    "    for row in old_X:\n",
    "        X.append(old_X[:n_col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmls_train_dir = \"./zad4_xmls/wiki_train_34_categories_results_wcrft2/\"\n",
    "xmls_test_dir = \"./zad4_xmls/wiki_test_34_categories_results_wcrft2/\"\n",
    "wordsDf = createWordsDf(xmls_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsDf = pd.read_csv(\"wordsDf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6889/6889 [02:03<00:00, 55.71it/s] \n",
      "100%|██████████| 2957/2957 [00:59<00:00, 49.67it/s]\n"
     ]
    }
   ],
   "source": [
    "mostFreq = list(getMostFreq(wordsDf, \"rzecz\", 1000)['base'])\n",
    "X_train_1000, y_train = createDataset(xmls_train_dir, mostFreq)\n",
    "X_test_1000, y_test = createDataset(xmls_test_dir, mostFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56684492, 0.64454976, 0.31481481, 0.55319149, 0.32116788,\n",
       "       0.35555556, 0.53744493, 0.5106383 , 0.24836601, 0.39800995,\n",
       "       0.72277228, 0.49746193, 0.28      , 0.60714286, 0.51666667,\n",
       "       0.4260355 , 0.70857143, 0.58385093, 0.67080745, 0.47572816,\n",
       "       0.50314465, 0.23529412, 0.69005848, 0.62857143, 0.31521739,\n",
       "       0.7032967 , 0.7388535 , 0.66666667, 0.69565217, 0.63101604,\n",
       "       0.73366834, 0.72941176, 0.35294118, 0.14457831, 0.        ,\n",
       "       0.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_1000, y_train)\n",
    "y_pred = clf.predict(X_test_1000)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56684492, 0.64454976, 0.31481481, 0.55319149, 0.32116788,\n",
       "       0.35555556, 0.53744493, 0.5106383 , 0.24836601, 0.39800995,\n",
       "       0.72277228, 0.49746193, 0.28      , 0.60714286, 0.51666667,\n",
       "       0.4260355 , 0.70857143, 0.58385093, 0.67080745, 0.47572816,\n",
       "       0.50314465, 0.23529412, 0.69005848, 0.62857143, 0.31521739,\n",
       "       0.7032967 , 0.7388535 , 0.66666667, 0.69565217, 0.63101604,\n",
       "       0.73366834, 0.72941176, 0.35294118, 0.14457831, 0.        ,\n",
       "       0.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_1000, y_train)\n",
    "y_pred = clf.predict(X_test_1000)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
